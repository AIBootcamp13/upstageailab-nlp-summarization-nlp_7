# ğŸ“Œ Dialogue Summarization Baseline

## Team

| ![ë°•íŒ¨ìº ](https://avatars.githubusercontent.com/u/156163982?v=4) | ![ì´íŒ¨ìº ](https://avatars.githubusercontent.com/u/156163982?v=4) | ![ìµœíŒ¨ìº ](https://avatars.githubusercontent.com/u/156163982?v=4) | ![ê¹€íŒ¨ìº ](https://avatars.githubusercontent.com/u/156163982?v=4) | ![ì˜¤íŒ¨ìº ](https://avatars.githubusercontent.com/u/156163982?v=4) |
|:----------------------------------------------------------------:|:----------------------------------------------------------------:|:----------------------------------------------------------------:|:----------------------------------------------------------------:|:----------------------------------------------------------------:|
| [ë°•íŒ¨ìº ](https://github.com/UpstageAILab) | [ì´íŒ¨ìº ](https://github.com/UpstageAILab) | [ìµœíŒ¨ìº ](https://github.com/UpstageAILab) | [ê¹€íŒ¨ìº ](https://github.com/UpstageAILab) | [ì˜¤íŒ¨ìº ](https://github.com/UpstageAILab) |
| íŒ€ì¥, ì´ê´„ ê¸°íš | ë°ì´í„° ë¶„ì„, EDA | ëª¨ë¸ë§, íŒŒì¸íŠœë‹, ì„±ëŠ¥ ê°œì„  | ì‹¤í—˜ ìë™í™”, ìŠ¤í¬ë¦½íŠ¸ ê°œë°œ | ì‹¤í—˜ ê´€ë¦¬, ë¦¬í¬íŠ¸ ì •ë¦¬ ë° ë°œí‘œìë£Œ ì œì‘ |

---

## 0. Overview

### Environment

- Python 3.10  
- CUDA 11.8  
- PyTorch 2.7.1  
- Huggingface Transformers 4.41.0  
- Datasets 4.0.0  
- Bitsandbytes 0.46.1  
- Accelerate 0.29.3  

### Requirements

```bash
pip install -r requirements.txt
```
 `requirements.txt`:
```
pandas==2.1.4
numpy==1.23.5
wandb==0.16.1
tqdm==4.66.1
pytorch_lightning==2.1.2
transformers[torch]>=4.41.0
rouge==1.0.1
jupyter==1.0.0
jupyterlab==4.0.9
python-dotenv==1.0.1
gradio==5.38.2
seaborn
nltk
konlpy
scikit-learn
umap-learn
hdbscan
sentencepiece==0.2.0
peft==0.16.0
datasets==4.0.0
accelerate>=0.24.0
bitsandbytes>=0.46.1
```

---

## 1. Competition Info

### Overview

- ì œê³µëœ 500ê°œì˜ ëŒ€í™”ë¬¸ì„ ìš”ì•½í•˜ëŠ” NLP íƒœìŠ¤í¬  
- ë‹¤ì–‘í•œ ì£¼ì œì˜ ëŒ€í™”ë¬¸ì„ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” ëª¨ë¸ ê°œë°œì´ ëª©í‘œ  
- ì¶”ë¡  ê²°ê³¼ëŠ” 500ê°œì˜ ìš”ì•½ë¬¸ì„ `.csv`ë¡œ ì œì¶œ

### Timeline

- July 25, 2025 - ëŒ€íšŒ ì‹œì‘  
- August 6, 2025 - ì œì¶œ ë§ˆê°  

---

## 2. Components

### Directory Structure

```
.
â”œâ”€â”€ config/
â”œâ”€â”€ data/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ KJB/
â”œâ”€â”€ script/ # gradioë¥¼ í™œìš©í•œ ê²°ê³¼ ë¶„ì„ script ë“±
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset/           # ë°ì´í„° ì „ì²˜ë¦¬, ë¡œë”, í† í¬ë‚˜ì´ì €
â”‚   â”‚   â””â”€â”€ preprocess.py
â”‚   â”‚   â””â”€â”€ loader.py
â”‚
â”‚   â”œâ”€â”€ model/             # ëª¨ë¸ ì•„í‚¤í…ì²˜ ë° ë¡œë”©
â”‚   â”‚   â””â”€â”€ base_model.py
â”‚   â”‚   â””â”€â”€ lora_wrapper.py
â”‚   â”‚   â””â”€â”€ peft_loader.py
â”‚
â”‚   â”œâ”€â”€ train/             # í•™ìŠµ ë¡œì§
â”‚   â”‚   â””â”€â”€ train_qlora.py
â”‚   â”‚   â””â”€â”€ trainer.py
â”‚
â”‚   â”œâ”€â”€ evaluation/        # í‰ê°€ ë° ë©”íŠ¸ë¦­
â”‚   â”‚   â””â”€â”€ evaluator.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚
â”‚   â”œâ”€â”€ inference/         # ì¶”ë¡  ë° ìƒì„±
â”‚   â”‚   â””â”€â”€ infer.py
â”‚   â”‚   â””â”€â”€ generator.py
â”‚
â”‚   â”œâ”€â”€ util/              # ê³µí†µ ìœ í‹¸ í•¨ìˆ˜
â”‚   â”‚   â””â”€â”€ collator.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ config_loader.py
â”‚
â”‚   â””â”€â”€ main.py            # ì‹¤í–‰ ì§„ì…ì  (ì˜ˆ: argparse ê¸°ë°˜ ì „ì²´ íŒŒì´í”„ë¼ì¸)
â”œâ”€â”€ .env.template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt

```

---

## 3. Data Description

### Dataset Overview

- `train.csv`: 12457ê°œ ëŒ€í™”ë¬¸ + ìš”ì•½  
- `dev.csv`: 500ê°œ ëŒ€í™”ë¬¸ + ìš”ì•½
- 'train.csv': 500ê°œ ëŒ€í™”ë¬¸  
- ëŒ€í™” í˜•ì‹: turn ê¸°ë°˜ (`#Person1#: ...`, `#Person2#: ...`)

### EDA

- ë¬¸ì¥ ê¸¸ì´ ë¶„í¬ ë¶„ì„: dialogueì™€ summaryì˜ ê¸¸ì´ ë¶„ì„
 <img width="453" height="292" alt="image" src="https://github.com/user-attachments/assets/93e79264-a39f-4a28-af9e-8cefd9832d11" />
- coverage ë¶„ì„: ìš”ì•½ë¬¸ì˜ ë‹¨ì–´ ì¤‘ì— **ì›ë¬¸ì— ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ë¥¼ ì‚¬ìš©í•œ ë¹„ìœ¨(Coverage)** í™•ì¸
 <img width="376" height="316" alt="image" src="https://github.com/user-attachments/assets/d743d452-e5e2-4da0-a60c-691c8e72f9dd" />

- coverageì— ë”°ë¥¸ ìš”ì•½ ë‚œì´ë„ ë¶„ì„: Coverage ratioë¥¼ 5ê°œì˜ ì˜ì—­ìœ¼ë¡œ binningí•˜ì—¬ ê° ì˜ì—­ì—ì„œ ëª¨ë¸ ì˜ˆì¸¡ í›„ rouge score í™•ì¸
<img width="388" height="339" alt="image" src="https://github.com/user-attachments/assets/a85a86a1-93b5-451e-9d26-4c0cdd096479" />

### Data Processing

- íŠ¹ìˆ˜ ë¬¸ì ì œê±°, ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬  
- í…œí”Œë¦¿ ì‚½ì…  
  ```
  ### Instruction: ë‹¤ìŒ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì¤˜.
  ### Input:
  (ëŒ€í™”)
  ### Output:
  ```
- Truncation ë° max_length ì§€ì •

### Data Augumentation

- ì†ŒëŸ‰ì˜ ë¼ë²¨ë§ ë°ì´í„°ë¥¼ ê·¹ë³µí•˜ê³  ëª¨ë¸ ì¼ë°˜í™” ëŠ¥ë ¥ í–¥ìƒ
- êµ¬ì–´ì²´ í‘œí˜„ì˜ ë‹¤ì–‘ì„± í™•ë³´ ë° ë¬¸ì²´ ì¼ê´€ì„± ìœ ì§€

#### ì‚¬ìš©í•œ ê¸°ë²•: Upstage Solar API (Solar LLM)
- Dialogue Paraphrasing
	- í‘œí˜„ ë‹¤ì–‘í™”ë¥¼ ìœ„í•œ Dialogue ì¬ì‘ì„±
- Summary Rewrite:
	- ë™ì¼ ìš”ì•½ ëŒ€ìƒì— ëŒ€í•œ ë‹¤ì–‘í•œ ìš”ì•½ ìƒì„±

####  íŒŒë¼ë¯¸í„° ì„¤ì •

```
temperature: 1.1       # ë‹¤ì–‘ì„± í™•ë³´ 
top_p: 0.9             # ì˜ë¯¸ ë³´ì¡´ 
frequency_penalty: 0.1 # ì¤‘ë³µ ì–µì œ
```
#### Few-shot Prompting ì ìš©
- Solar APIì˜ instruction êµ¬ì¡°ì— ë§ì¶° "user â†’ assistant" í¬ë§· êµ¬ì„±
- ìš”ì•½ ë¬¸ì²´ ë° êµ¬ì¡°ë¥¼ ì¼ê´€ë˜ê²Œ ìœ ì§€í•˜ë©° SFT ì¹œí™”ì  ë°ì´í„° í™•ë³´

---

## 4. Modeling

### Model Description
ì´ 2ê°€ì§€ ëª¨ë¸ë¡œ ì‹¤í—˜ ì§„í–‰

### Baseline Model : `KoBART`
- ëª¨ë¸ êµ¬ì¡°: Encoder-Decoder
- íŠ¹ì§•:
	- ëŒ€í™”ì²´ì˜ ê¸°ë³¸ ë¬¸ë²• ë° êµ¬ì¡° í•™ìŠµ
	- HuggingFace ê¸°ë°˜ fine-tuning ì§„í–‰
- í•œê³„ì :
	- ê¸´ dialogueì˜ í•µì‹¬ ë¬¸ë§¥ì„ ì¡ì§€ ëª»í•˜ê³  ìš”ì•½ ì •í™•ë„(ROUGE) ë‚®ìŒ
	- ì¸ì½”ë”© ê³¼ì •ì—ì„œ ì˜ë¯¸ ì†ì‹¤ ë°œìƒ â†’ Context íŒŒì•… ë¯¸í¡

####ë„ë©”ì¸ ì ì‘ ì‚¬ì „í•™ìŠµ (TAPT)
- ë„ì… ë°°ê²½
	- ëŒ€í™”ì²´ íŠ¹ìœ  ì–´íœ˜/êµ¬ë¬¸ êµ¬ì¡°ê°€ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì— ì ê²Œ ë°˜ì˜ë¨
	- ëŒ€í™”ì²´ì— íŠ¹í™”ëœ encoderë¥¼ íšë“í•˜ê³  downstream ì„±ëŠ¥ í–¥ìƒ
- ë°©ì‹
	- KoBART ëª¨ë¸ì˜ encoderì— ëŒ€í•´ Masked Language Modeling(MLM) ê¸°ë°˜ ë¹„ì§€ë„ í•™ìŠµ
	- ì´í›„ ìš”ì•½ íƒœìŠ¤í¬ë¥¼ ìœ„í•œ fine-tuning ìˆ˜í–‰
- ê¸°ëŒ€ íš¨ê³¼
	- êµ¬ì–´ì²´ ë¬¸ë§¥ íŒŒì•…ë ¥ í–¥ìƒ
	- ì†ŒëŸ‰ì˜ ë ˆì´ë¸”ë§Œìœ¼ë¡œë„ ë†’ì€ ì„±ëŠ¥ ìœ ì§€



### Baseline Model : `Upstage/SOLAR-10.7B-Instruct`
- **ëª¨ë¸ êµ¬ì¡°**: Decoder-only LLM (GPT ê³„ì—´)
- **íŠ¹ì§•**:
  - ë‹¤êµ­ì–´ instruction tuning ê¸°ë°˜ ëª¨ë¸
  - Upstageì—ì„œ ê³µê°œí•œ LLMìœ¼ë¡œ, `### Instruction: ... ### Input: ... ### Output:` í¬ë§·ì— ê°•í•¨
  - HuggingFaceì—ì„œ `transformers` + `QLoRA`ë¡œ íš¨ìœ¨ì  íŒŒì¸íŠœë‹ ê°€ëŠ¥
- **í•œê³„ì **:
  - ê±°ëŒ€í•œ íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµì— í•„ìš”í•œ ìì›ì´ ë§¤ìš° ë§ë‹¤
  - ì¶”ë¡  ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤

---

#### Instruction ê¸°ë°˜ ë¯¸ì„¸ì¡°ì • (SFT with QLoRA)
- **ë„ì… ë°°ê²½**  
  - ê¸°ì¡´ kobart ëª¨ë¸ì˜ ìš”ì•½ ê²°ê³¼ë¥¼ ë³´ì•˜ì„ ë•Œ, dialogueì˜ í•µì‹¬ ë¬¸ë§¥ì„ íŒŒì•…í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ìì£¼ ë°œìƒ  
  - LLM ëª¨ë¸ ìì²´ë¥¼ downstream taskì— í•™ìŠµì‹œí‚¨ë‹¤ë©´ í•µì‹¬ ë¬¸ë§¥ì„ ì˜ íŒŒì•…í•˜ë©´ì„œë„ ê¸°ì¡´ì˜ ìš”ì•½ í˜•ì‹ì— ë§ê²Œ ì˜ˆì¸¡ ê°€ëŠ¥
  - QLoRAë¥¼ í†µí•´ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ í™•ë³´í•˜ë©´ì„œë„ ëŒ€í˜• ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì • ê°€ëŠ¥
  - ë¹„ìŠ·í•œ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ íƒ€ ëª¨ë¸ ëŒ€ë¹„ ì›”ë“±í•œ ì„±ëŠ¥

- **ë°©ì‹**
  - SOLAR 10.7B ëª¨ë¸ì— ëŒ€í•´ `QLoRA` ê¸°ë°˜ SFT ìˆ˜í–‰  
  - Prompt í…œí”Œë¦¿ ì‚¬ìš©:
    ```
    ### Instruction: ë‹¤ìŒ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì¤˜.
    ### Input:
    #Person1#: ...
    #Person2#: ...
    ### Output:
    (ìš”ì•½)
    ```
  - LoRA ì ìš© ëŒ€ìƒ: `q`, `k`, `v`, `o`, `gate`, `down`, `up` ë“± í•µì‹¬ block í¬í•¨ -> full fine-tuningê³¼ ë¹„ìŠ·í•œ íš¨ê³¼ë¥¼ ì¤Œ

- **ê¸°ëŒ€ íš¨ê³¼**
  - instruction í¬ë§· ì´í•´ë ¥ ê·¹ëŒ€í™” â†’ ëª…ì‹œì  ìš”ì•½ ëª…ë ¹ì— ê°•í•œ ë°˜ì‘  
  - ëŒ€ìš©ëŸ‰ íŒŒë¼ë¯¸í„°ë¥¼ í™œìš©í•´ ì •ë°€í•œ ë¬¸ë§¥ íŒŒì•… ê°€ëŠ¥  
  - ê¸°ì¡´ KoBART ëŒ€ë¹„ ROUGE í–¥ìƒ ë° ë°œí™” ê°„ ê´€ê³„ ì¸ì‹ë ¥ ì¦ê°€ 

### Modeling Process

#### SOLAR + QLoRA í•™ìŠµ
1. í•™ìŠµ í”„ë¡¬í”„íŠ¸ êµ¬ì„±(right padding):
    ```
    ### Instruction: ë‹¤ìŒ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì¤˜.
    ### Input:
    #Person1#: ...
    #Person2#: ...
    ### Output:
    {summary}
    ```

2. í•™ìŠµ:
   - Trainer ê¸°ë°˜ QLoRA fine-tuning (1 epoch)  
   - summary ë¶€ë¶„ë§Œ labelingí•´ì„œ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ì„œëŠ” loss ê³„ì‚° ëª»í•˜ê²Œ ë§‰ìŒ
   - gradient_checkpoint, prepare_model_for_kbit_training, use_cache=False ì˜µì…˜ ë“±ì„ í†µí•´ gpu ë©”ëª¨ë¦¬ ìµœëŒ€í•œ í™•ë³´
   - bs=2
   - lora_r:8, lora_alpha:32, dropout:0.05  

3. ì¶”ë¡ :
   - grid ê¸°ë°˜ ìƒì„±
   - bs=2
   - ê²°ê³¼ ë¬¸ì¥ split í›„ summary ë¶€ë¶„ë§Œ ì €ì¥í•  ìˆ˜ ìˆë„ë¡ post process  
   - `.csv` í˜•íƒœë¡œ ê²°ê³¼ ì €ì¥  

---

## 5. Result

### Leaderboard
- **ìˆœìœ„**:  1ìœ„  

<p align="center">
  <img src="https://github.com/user-attachments/assets/fbcb6795-de9b-40b9-9241-14c9f4b276bd" width="45%" />
  <img src="https://github.com/user-attachments/assets/ac7af015-48a0-473b-9992-11b82c361bec" width="45%" />
</p>

### Presentation

- [ğŸ“ ë°œí‘œìë£Œ (PDF)](https://drive.google.com/file/d/1KCp7ExnV50lV6QPp5LCabN_6-64wZWKT/view?usp=sharing)

### Reference

- [Huggingface Transformers](https://huggingface.co/docs)
- [Upstage/SOLAR ëª¨ë¸ ì¹´ë“œ]([https://huggingface.co/Upstage/SOLAR-10.7B-Instruct](https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0))
- [QLoRA ë…¼ë¬¸](https://arxiv.org/abs/2305.14314)
